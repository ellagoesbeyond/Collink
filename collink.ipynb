{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8a4c56",
   "metadata": {},
   "source": [
    "# Collink | the video call Add-on "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a659d2",
   "metadata": {},
   "source": [
    "    Have you ever been in a Video Call within your company or university and came across people u don't know? \n",
    "\n",
    "    I've always been curious about former colleagues or students in my projects or courses. \n",
    "\n",
    "    With the collink Add-on you should be able to identify the LinkedIn profile page of your colleague by scanning his/her face. \n",
    "    \n",
    "<img src=\"funny.gif\" width=\"200\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00833848",
   "metadata": {},
   "source": [
    "                     okay jokes aside. the algorithm is a low level GUI version of the ideal idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27dbcc2",
   "metadata": {},
   "source": [
    "<img src=\"zoom.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a3829",
   "metadata": {},
   "source": [
    "                                                Lets get into it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59207d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Here are the results -------------------------\n",
      "\n",
      "The person could be:  \u001b[1m\u001b[32mJoyce Bride\u001b[0m\n",
      "working as a  \u001b[1m\u001b[34mProgram Associate at Ironhack\u001b[0m in  \u001b[1m\u001b[34mBerlin, Berlin, Germany\u001b[0m\n",
      "http://www.linkedin.com/in/ACoAACI02BgBjcFGyDcj7o2zXkJ5U3jaj0nJ1pM\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "import imutils \n",
    "import requests\n",
    "import time \n",
    "import os\n",
    "import random\n",
    "import fnmatch\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import difflib\n",
    "import json \n",
    "from pprint import pprint\n",
    "import webbrowser\n",
    "\n",
    "import config\n",
    "from linkedin_api import Linkedin\n",
    "import sys\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from google_images_search import GoogleImagesSearch\n",
    "\n",
    "from termcolor import colored as col\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "import urllib\n",
    "\n",
    "ended=False ##. variable to break th emain loop \n",
    "api=Linkedin(\"elisabeth.oeljeklaus@web.de\",config.password)\n",
    "\n",
    "with open(\"get_known_people_encodings.pickle\", \"rb\") as f:\n",
    "    known_face_encodings,known_face_names =pickle.load(f)\n",
    "    \n",
    "    \n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "cv2.CAP_PROP_BUFFERSIZE \n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    #rectangle with description\n",
    "    cv2.rectangle(frame, (0, 0), (350,50), (127, 120, 121), cv2.FILLED)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(frame, \"for results press L\", (0, 35), font, 1.0, (255, 255, 255), 1)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        \n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        if(len(face_encodings)>0):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encodings[0])\n",
    "\n",
    "\n",
    "            # If a match was found in known_face_encodings, just use the first one.\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = str(known_face_names[first_match_index])\n",
    "                indx= name.find(\"_\")\n",
    "                l_name=name[indx+1:]\n",
    "                f_name=name[:indx]\n",
    "\n",
    "\n",
    "            else: \n",
    "                x=\"Face does not exist in database.\"\n",
    "     \n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (98, 229, 111), 2)\n",
    "        \n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (98, 229, 111), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, \"searching . . .\", (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    cv2.startWindowThread()\n",
    "    cv2.imshow('Video', frame) # important to put below all cv2. instructions\n",
    "    cv2.setWindowProperty('Video', cv2.WND_PROP_VISIBLE, 1)\n",
    "\n",
    "    cv2.setWindowProperty('Video', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    # Hit 'l' on the keyboard to get LinkedIn profile!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('l'):\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(5)\n",
    "        video_capture.release()\n",
    "        person_search=api.search_people(keyword_first_name=f_name, keyword_last_name=l_name)\n",
    "        res_url= person_search[0][\"urn_id\"]\n",
    "        res_name= person_search[0][\"name\"]\n",
    "        job=person_search[0][\"jobtitle\"]\n",
    "        loc=person_search[0][\"location\"]\n",
    "        info=api.get_profile(res_url)\n",
    "        industry=info[\"industryName\"]\n",
    "        company = info[\"experience\"][0][\"companyName\"]\n",
    "        job_=info[\"experience\"][0][\"title\"]\n",
    "        \n",
    "        print(\"------------------ Here are the results -------------------------\")\n",
    "        print()\n",
    "        print(\"The person could be: \",col(res_name,\"green\",attrs=[\"bold\"]))\n",
    "        print(\"working as a \",col(job,\"blue\",attrs=[\"bold\"]),\"in \",col(loc,\"blue\",attrs=[\"bold\"]))\n",
    "        print(\"http://www.linkedin.com/in/\"+res_url)\n",
    "        \n",
    "   \n",
    "        #open linkedin tab in browser\n",
    "        webbrowser.open(\"http://www.linkedin.com/in/\"+res_url)\n",
    "        \n",
    "        #open new window with results\n",
    "        path = \"pics/GUI_interface.jpeg\"\n",
    "        image = cv2.imread(path)\n",
    "        height, width, channels = image.shape\n",
    "        start_point = (0,0)\n",
    "        end_point = (width, height)\n",
    "        color = (255,255,255)\n",
    "        thickness = 5\n",
    "\n",
    "        image = cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "        \n",
    "        while True: \n",
    "            #cv2.setWindowProperty(\"fullscreen\", cv.WND_PROP_FULLSCREEN,cv.WINDOW_FULLSCREEN)\n",
    "            cv2.imshow('Result',image)\n",
    "            cv2.setWindowProperty('Result', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(image, (\"Result\"), (680, 238), font, 2.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"Name: \"+res_name), (311, 318), font, 1.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"Industry: \"+industry), (311, 357), font, 1.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"Job: \"+job_), (311, 396), font, 1.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"Company: \"+company), (311, 435), font, 1.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"Location: \"+loc), (311, 474), font, 1.0, (255, 255, 255), 1)\n",
    "            cv2.putText(image, (\"to close press 'q'\"), (734, 577), font, 1.0, (255, 255, 255), 1)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                ended=True\n",
    "                print(\"test\")\n",
    "                #cv2.destroyWindow(\"Result\")\n",
    "                #cv2.destroyAllWindows()\n",
    "                #cv2.waitKey(1)\n",
    "                break\n",
    "       \n",
    "    elif cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    if ended: \n",
    "        print(\"finished the main loop\")\n",
    "        break    \n",
    "\n",
    "print(\"program finished...\")\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "#video_capture.release()\n",
    "#raise KeyboardInterrupt\n",
    "#assert(False)\n",
    "#!jupyter notebook stop\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f499e5b4",
   "metadata": {},
   "source": [
    "# The current workflow \n",
    "\n",
    "\n",
    "1. Gather a database from known faces \n",
    "        - Do it manually (download jpeg/jpg and name the file with name)\n",
    "        \n",
    "2. Run the encode_people_faces function \n",
    "        - Function and this sub workflow is stored in extra jupyter notebook\n",
    "        - Save the functions output with pickle \n",
    "        \n",
    "3. Run the main algorithm \n",
    "       - Import the alle necessarly face_recognition, selenium, pickle, cv2\n",
    "       - comparing live face with known faces in data base \n",
    "       - find match \n",
    "       - open LinkedIn profile by using LinkedIn API \n",
    "       - open results window with open cv \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
